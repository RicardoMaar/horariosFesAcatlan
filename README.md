# ğŸ“š Horarios FES AcatlÃ¡n

Sistema integral para consultar y gestionar horarios acadÃ©micos de la Facultad de Estudios Superiores AcatlÃ¡n (UNAM). Permite a los estudiantes crear horarios personalizados, visualizar conflictos de horarios y exportar sus calendarios.

## ğŸš€ CaracterÃ­sticas

- **VisualizaciÃ³n interactiva**: Calendario semanal con vista responsiva para desktop y mÃ³vil
- **GestiÃ³n de materias**: SelecciÃ³n mÃºltiple con detecciÃ³n automÃ¡tica de traslapes
- **ExportaciÃ³n**: PDF, Excel y capturas de pantalla del horario
- **Persistencia**: Los horarios se guardan automÃ¡ticamente en el navegador
- **BÃºsqueda inteligente**: Filtrado por nombre de materia, profesor o cÃ³digo
- **Colores personalizables**: Sistema de colores determinÃ­stico para cada materia
- **OptimizaciÃ³n**: CachÃ© inteligente y rate limiting para mejor rendimiento

## ğŸ—ï¸ Arquitectura

### Frontend (React + Vite)
- **Framework**: React 19 con Vite para desarrollo rÃ¡pido
- **Estado**: Zustand para gestiÃ³n de estado global con persistencia
- **UI**: Tailwind CSS + Radix UI para componentes accesibles
- **Animaciones**: Framer Motion para transiciones fluidas
- **ExportaciÃ³n**: html2canvas, jsPDF y xlsx para mÃºltiples formatos

### Backend (FastAPI)
- **API REST**: FastAPI con documentaciÃ³n automÃ¡tica OpenAPI
- **CachÃ©**: Sistema de cachÃ© en memoria con validaciÃ³n ETags
- **OptimizaciÃ³n**: Rate limiting (100 req/min) y compresiÃ³n GZip
- **CORS**: Configurado para producciÃ³n y desarrollo local
- **Salud**: Endpoints de health check y status

### Scraper (Node.js)
- **AutomatizaciÃ³n**: Extrae datos del sistema acadÃ©mico oficial
- **Procesamiento**: JSDOM para parsing HTML y estructuraciÃ³n de datos
- **Almacenamiento**: Guarda datos en JSON y opcionalmente en Supabase
- **Scheduling**: Nodemon para desarrollo con auto-reload

## ğŸ“¦ InstalaciÃ³n

### Prerrequisitos
- Node.js 18+
- Python 3.8+
- npm o yarn

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/horariosFesAcatlan.git
cd horariosFesAcatlan
```

### 2. Configurar Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Configurar Frontend
```bash
cd frontend
npm install
```

### 4. Configurar Scraper
```bash
cd backend/scraper
npm install
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de entorno

#### Backend
Crear archivo `.env` en `/backend/`:
```env
HORARIOS_JSON_URL=https://tu-url-de-datos.com/horarios.json
PORT=8000
```

#### Scraper (opcional)
Crear archivo `.env` en `/backend/scraper/`:
```env
SUPABASE_URL=tu_supabase_url
SUPABASE_ANON_KEY=tu_supabase_key
```

## ğŸš€ Uso

### Desarrollo

1. **Ejecutar Backend**:
```bash
cd backend
source venv/bin/activate
python main.py
```

2. **Ejecutar Frontend**:
```bash
cd frontend
npm run dev
```

3. **Ejecutar Scraper** (opcional):
```bash
cd backend/scraper
npm run dev
```

### ProducciÃ³n

1. **Build Frontend**:
```bash
cd frontend
npm run build
```

2. **Deploy Backend**:
```bash
cd backend
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker
```

## ğŸ“š API Endpoints

### Base URL: `/api`

- `GET /status` - Estado del servicio y fecha de actualizaciÃ³n
- `GET /carreras` - Lista de todas las carreras disponibles
- `GET /horarios/{carrera_codigo}` - Horarios de una carrera especÃ­fica
- `GET /health` - Health check del servicio

### Ejemplo de respuesta:
```json
{
  "carreras": {
    "20121": {
      "codigo": "20121",
      "nombre": "Arquitectura"
    }
  }
}
```

## ğŸ› ï¸ Scripts Disponibles

### Frontend
- `npm run dev` - Servidor de desarrollo (puerto 3000)
- `npm run build` - Build para producciÃ³n
- `npm run preview` - Preview del build
- `npm run lint` - AnÃ¡lisis de cÃ³digo con ESLint

### Backend
- `python main.py` - Ejecutar servidor FastAPI
- `uvicorn main:app --reload` - Servidor con auto-reload

### Scraper
- `npm run dev` - Ejecutar scraper con auto-reload
- `npm run lint` - AnÃ¡lisis de cÃ³digo

## ğŸ—‚ï¸ Estructura del Proyecto

```
horariosFesAcatlan/
â”œâ”€â”€ frontend/                 # AplicaciÃ³n React
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # Componentes React
â”‚   â”‚   â”‚   â”œâ”€â”€ calendario/   # Componentes del calendario
â”‚   â”‚   â”‚   â””â”€â”€ listaMaterias/ # Componentes de lista
â”‚   â”‚   â”œâ”€â”€ hooks/           # Custom hooks
â”‚   â”‚   â”œâ”€â”€ store/           # GestiÃ³n de estado (Zustand)
â”‚   â”‚   â”œâ”€â”€ utils/           # Utilidades y helpers
â”‚   â”‚   â””â”€â”€ constants/       # Constantes de la aplicaciÃ³n
â”‚   â”œâ”€â”€ public/              # Archivos estÃ¡ticos
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”œâ”€â”€ main.py             # Punto de entrada de la API
â”‚   â”œâ”€â”€ requirements.txt    # Dependencias Python
â”‚   â””â”€â”€ scraper/            # Scraper Node.js
â”‚       â”œâ”€â”€ scraper.js      # LÃ³gica principal del scraper
â”‚       â”œâ”€â”€ upload.js       # Upload a Supabase
â”‚       â”œâ”€â”€ materias/       # Datos extraÃ­dos
â”‚       â””â”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ¨ CaracterÃ­sticas TÃ©cnicas

### Frontend
- **Responsive Design**: Optimizado para desktop y mÃ³vil
- **PWA Ready**: Configurado para Progressive Web App
- **IndexedDB**: Almacenamiento local para mejor rendimiento
- **Lazy Loading**: Carga optimizada de componentes
- **Error Boundaries**: Manejo robusto de errores

### Backend
- **Async/Await**: Operaciones asÃ­ncronas para mejor rendimiento
- **Middleware**: CORS, compresiÃ³n GZip y rate limiting
- **CachÃ© Inteligente**: ETags y Last-Modified headers
- **DocumentaciÃ³n**: OpenAPI/Swagger automÃ¡tica en `/docs`

### Scraper
- **DOM Parsing**: ExtracciÃ³n robusta de datos HTML
- **Error Handling**: Manejo de fallos de red y parsing
- **Data Validation**: ValidaciÃ³n de estructura de datos
- **Flexible Output**: JSON local y cloud storage

## ğŸ”’ Seguridad

- Rate limiting para prevenir abuso de la API
- ValidaciÃ³n de entrada en todos los endpoints
- CORS configurado especÃ­ficamente para dominios autorizados
- SanitizaciÃ³n de datos del scraper

## ğŸ“ˆ Rendimiento

- CachÃ© en memoria con invalidaciÃ³n inteligente
- CompresiÃ³n GZip para reducir transferencia de datos
- Persistencia local para reducir llamadas a la API
- Lazy loading de componentes React
- Bundle optimization con Vite

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-caracteristica`)
3. Commit tus cambios (`git commit -m 'Agregar nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/nueva-caracteristica`)
5. Abre un Pull Request

### Guidelines de desarrollo
- Usar ESLint para mantener consistencia de cÃ³digo
- Escribir tests para nuevas funcionalidades
- Documentar cambios en la API
- Seguir convenciones de commit semÃ¡ntico

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Ricardo Martinez** - *Desarrollo inicial* - [@ricardomartinez](https://github.com/ricardomartinez)

## ğŸ™ Agradecimientos

- UNAM FES AcatlÃ¡n por los datos acadÃ©micos
- Comunidad de React y FastAPI
- Contribuidores del proyecto

## ğŸ› Reportar Issues

Si encuentras algÃºn problema o tienes sugerencias:
1. Revisa los [issues existentes](https://github.com/tu-usuario/horariosFesAcatlan/issues)
2. Crea un nuevo issue con etiquetas apropiadas
3. Incluye pasos para reproducir el problema

## ğŸ“Š Estado del Proyecto

- âœ… Frontend completo y funcional
- âœ… Backend API REST con cachÃ©
- âœ… Scraper automatizado
- âœ… ExportaciÃ³n mÃºltiple formato
- ğŸ”„ PWA en desarrollo
- ğŸ”„ Tests unitarios en desarrollo
- ğŸ”„ CI/CD pipeline en desarrollo

---

â­ Si este proyecto te ha sido Ãºtil, no olvides darle una estrella en GitHub!